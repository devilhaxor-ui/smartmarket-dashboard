import streamlit as st
import feedparser
from datetime import datetime
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from deep_translator import GoogleTranslator
from bs4 import BeautifulSoup

# à¸à¹ˆà¸­à¸™à¹à¸›à¸¥ à¹ƒà¸«à¹‰à¸¥à¹‰à¸²à¸‡ HTML
def clean_html(raw_html):
    soup = BeautifulSoup(raw_html, "html.parser")
    return soup.get_text()

# ---------- CONFIG ----------
RSS_FEEDS = [
    "https://news.google.com/rss/search?q=gold+price+OR+XAUUSD&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=silver+price+OR+XAGUSD&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=bitcoin+OR+BTCUSD&hl=en-US&gl=US&ceid=US:en"
]

ASSETS = {
    "à¸—à¸­à¸‡à¸„à¸³ (XAU)": ["gold", "xauusd", "bullion"],
    "à¹€à¸‡à¸´à¸™ (XAG)": ["silver", "xagusd"],
    "à¸šà¸´à¸•à¸„à¸­à¸¢à¸™à¹Œ (BTC)": ["bitcoin", "btc", "crypto"]
}

analyzer = SentimentIntensityAnalyzer()
st.set_page_config(page_title="SmartMarket Daily Dashboard", layout="centered")

st.title("ğŸŒ SmartMarket Daily Dashboard")
st.write(f"à¸­à¸±à¸›à¹€à¸”à¸•à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {datetime.now().strftime('%d %B %Y, %H:%M')} à¸™.")
st.info("à¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹ˆà¸²à¸§à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸—à¸­à¸‡à¸„à¸³, à¹€à¸‡à¸´à¸™ à¹à¸¥à¸°à¸šà¸´à¸•à¸„à¸­à¸¢à¸™à¹Œ à¹à¸¥à¹‰à¸§à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹€à¸›à¹‡à¸™ **à¸ à¸²à¸©à¸²à¹„à¸—à¸¢**")

# ---------- FETCH NEWS ----------
@st.cache_data(ttl=3600)
def get_news():
    articles = []
    for url in RSS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for entry in feed.entries:
                # à¸—à¸³à¸„à¸§à¸²à¸¡à¸ªà¸°à¸­à¸²à¸” HTML à¹à¸¥à¸°à¹à¸›à¸¥à¸‚à¹ˆà¸²à¸§
                summary_text = clean_html(entry.get("summary", ""))
                try:
                    summary_th = GoogleTranslator(source='auto', target='th').translate(summary_text)
                except Exception:
                    summary_th = summary_text
                
                articles.append({
                    "title": entry.title,
                    "link": entry.link,
                    "summary": summary_th,
                    "published": entry.get("published", "")
                })
        except Exception as e:
            st.error(f"Error fetching feed {url}: {str(e)}")
    
    return articles

articles = get_news()

# ---------- ANALYZE ----------
results = {}
for asset_name, keywords in ASSETS.items():
    relevant = []
    sentiment_scores = []
    for a in articles:
        text_lower = (a["title"] + " " + a["summary"]).lower()
        if any(kw in text_lower for kw in keywords):
            vs = analyzer.polarity_scores(a["title"] + " " + a["summary"])
            sentiment_scores.append(vs["compound"])
            relevant.append(a)
    
    if sentiment_scores:
        avg_sent = sum(sentiment_scores) / len(sentiment_scores)
        if avg_sent > 0.1:
            tone = "ğŸŸ© à¹€à¸Šà¸´à¸‡à¸šà¸§à¸"
            trend = "Bullish"
        elif avg_sent < -0.1:
            tone = "ğŸŸ¥ à¹€à¸Šà¸´à¸‡à¸¥à¸š"
            trend = "Bearish"
        else:
            tone = "âšª à¹€à¸›à¹‡à¸™à¸à¸¥à¸²à¸‡"
            trend = "Neutral"
        results[asset_name] = {
            "sentiment": avg_sent,
            "tone": tone,
            "trend": trend,
            "articles": relevant
        }

# ---------- DISPLAY ----------
for asset_name, data in results.items():
    st.subheader(f"ğŸ”¹ {asset_name}")
    st.write(f"à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸‚à¹ˆà¸²à¸§: {data['tone']} (sentiment = {data['sentiment']:.2f})")
    st.write("**à¸ªà¸£à¸¸à¸›à¸‚à¹ˆà¸²à¸§:**")
    for art in data["articles"][:3]:  # à¹à¸ªà¸”à¸‡à¹à¸„à¹ˆ 3 à¸‚à¹ˆà¸²à¸§à¸¥à¹ˆà¸²à¸ªà¸¸à¸”
        st.markdown(f"ğŸ“° [{art['title']}]({art['link']})")
        st.write(f"â†’ {art['summary']}")
    st.markdown("---")

st.subheader("ğŸ“Š à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸•à¸¥à¸²à¸”à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸§à¸±à¸™à¸™à¸µà¹‰:")
for asset_name, data in results.items():
    st.write(f"{asset_name} = **{data['trend']}**")

st.caption("ğŸ§  à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸”à¹‰à¸§à¸¢ VADER sentiment + à¹à¸›à¸¥à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ˆà¸²à¸ Google Translator + à¸‚à¹ˆà¸²à¸§ RSS")
