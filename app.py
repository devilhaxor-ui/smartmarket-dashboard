import streamlit as st
import feedparser
from datetime import datetime
from googletrans import Translator
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer

# ---------- CONFIG ----------
RSS_FEEDS = [
    "https://news.google.com/rss/search?q=gold+price+OR+XAUUSD&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=silver+price+OR+XAGUSD&hl=en-US&gl=US&ceid=US:en",
    "https://news.google.com/rss/search?q=bitcoin+OR+BTCUSD&hl=en-US&gl=US&ceid=US:en"
]

ASSETS = {
    "à¸—à¸­à¸‡à¸„à¸³ (XAU)": ["gold", "xauusd", "bullion"],
    "à¹€à¸‡à¸´à¸™ (XAG)": ["silver", "xagusd"],
    "à¸šà¸´à¸•à¸„à¸­à¸¢à¸™à¹Œ (BTC)": ["bitcoin", "btc", "crypto"]
}

analyzer = SentimentIntensityAnalyzer()
translator = Translator()

st.set_page_config(page_title="SmartMarket Daily Dashboard", layout="centered")

st.title("ğŸŒ SmartMarket Daily Dashboard")
st.write(f"à¸­à¸±à¸›à¹€à¸”à¸•à¸¥à¹ˆà¸²à¸ªà¸¸à¸”: {datetime.now().strftime('%d %B %Y, %H:%M')} à¸™.")
st.info("à¸£à¸§à¸šà¸£à¸§à¸¡à¸‚à¹ˆà¸²à¸§à¸¥à¹ˆà¸²à¸ªà¸¸à¸”à¹€à¸à¸µà¹ˆà¸¢à¸§à¸à¸±à¸šà¸—à¸­à¸‡à¸„à¸³, à¹€à¸‡à¸´à¸™ à¹à¸¥à¸°à¸šà¸´à¸•à¸„à¸­à¸¢à¸™à¹Œ à¹à¸¥à¹‰à¸§à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¹€à¸›à¹‡à¸™ **à¸ à¸²à¸©à¸²à¹„à¸—à¸¢**")

# ---------- FETCH NEWS ----------
@st.cache_data(ttl=3600)
def get_news():
    articles = []
    for url in RSS_FEEDS:
        try:
            feed = feedparser.parse(url)
            for e in feed.entries[:10]:
                articles.append({
                    "title": e.get("title", ""),
                    "summary": e.get("summary", ""),
                    "link": e.get("link", ""),
                    "published": e.get("published", "")
                })
        except Exception:
            continue
    return articles

articles = get_news()

# ---------- ANALYZE ----------
results = {}
for asset_name, keywords in ASSETS.items():
    relevant = []
    sentiment_scores = []
    for a in articles:
        text_lower = (a["title"] + " " + a["summary"]).lower()
        if any(kw in text_lower for kw in keywords):
            vs = analyzer.polarity_scores(a["title"] + " " + a["summary"])
            sentiment_scores.append(vs["compound"])
            relevant.append(a)
    if sentiment_scores:
        avg_sent = sum(sentiment_scores) / len(sentiment_scores)
        if avg_sent > 0.1:
            tone = "ğŸŸ© à¹€à¸Šà¸´à¸‡à¸šà¸§à¸"
            trend = "Bullish"
        elif avg_sent < -0.1:
            tone = "ğŸŸ¥ à¹€à¸Šà¸´à¸‡à¸¥à¸š"
            trend = "Bearish"
        else:
            tone = "âšª à¹€à¸›à¹‡à¸™à¸à¸¥à¸²à¸‡"
            trend = "Neutral"
        results[asset_name] = {
            "sentiment": avg_sent,
            "tone": tone,
            "trend": trend,
            "articles": relevant
        }

# ---------- DISPLAY ----------
for asset_name, data in results.items():
    st.subheader(f"ğŸ”¹ {asset_name}")
    st.write(f"à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸‚à¹ˆà¸²à¸§: {data['tone']} (sentiment = {data['sentiment']:.2f})")
    st.write("**à¸ªà¸£à¸¸à¸›à¸‚à¹ˆà¸²à¸§:**")
    for art in data["articles"][:3]:
        st.markdown(f"ğŸ“° [{art['title']}]({art['link']})")
        try:
            summary_th = translator.translate(art["summary"], src='en', dest='th').text
        except Exception:
            summary_th = art["summary"]
        st.write(f"â†’ {summary_th}")
    st.markdown("---")

st.subheader("ğŸ“Š à¹à¸™à¸§à¹‚à¸™à¹‰à¸¡à¸•à¸¥à¸²à¸”à¹‚à¸”à¸¢à¸£à¸§à¸¡à¸§à¸±à¸™à¸™à¸µà¹‰:")
for asset_name, data in results.items():
    st.write(f"{asset_name} = **{data['trend']}**")

st.caption("ğŸ§  à¸§à¸´à¹€à¸„à¸£à¸²à¸°à¸«à¹Œà¸”à¹‰à¸§à¸¢ VADER sentiment + à¹à¸›à¸¥à¸­à¸±à¸•à¹‚à¸™à¸¡à¸±à¸•à¸´à¸ˆà¸²à¸ Google Translate + à¸‚à¹ˆà¸²à¸§ RSS")
